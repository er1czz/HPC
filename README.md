# Kaggle data challenge log
### 1. RMS Titanic Survival Prediction (testing water)
- random forest classification, **accuracy** score 0.81930 for training and 0.77033 for testing
- Accuracy score: higher score is better, testing score provided by Kaggle
- to-do: Monte Carlo to simulate the missing data, especially passenger age.
### 2 Ames House Price Prediction (data analysis practice)
- random forest regression, **RMLE** score 0.14319 for training and 0.18125 for testing 
- RMLE (Root Mean Squared Log Error): lower score is better, testing score provided by Kaggle
- to-do: exploratory data analysis and feature selection
### 3 IEEE-CIS Fraud Detection (in progress)

# Misc
### Monte Carlo
- MC calculation on Dice and Pi with Numpy Random
