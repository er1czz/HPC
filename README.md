# Kaggle data challenge log
### 1. RMS Titanic Survival Prediction
- random forest classification, **accuracy** score 0.81930 for training and 0.77033 for testing
- Accuracy score: higher score is better, testing score provided by Kaggle
- to-do: Monte Carlo to simulate the missing data, especially passenger age.
### 2 Ames House Price Prediction
- random forest regression, **RMLE** score 0.14319 for training and 0.18125 for testing 
- RMLE (Root Mean Squared Log Error): lower score is better, testing score provided by Kaggle
- to-do: exploratory data analysis and feature selection

